{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math\n",
    "import numpy as np\n",
    "from numpy.polynomial import chebyshev\n",
    "import sklearn.preprocessing as pp\n",
    "import sklearn.linear_model as lm\n",
    "import scipy as sp\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from corner import corner\n",
    "\n",
    "# Astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "# File manipulation\n",
    "import wget\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from threading import Thread\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fits(s):\n",
    "    fitsPattern = r\"apStar-.*\\.fits\\b\"\n",
    "    matches = re.match(fitsPattern, s)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fits_directory(fields):\n",
    "    fitsDir = './fits_files'\n",
    "    for field in fields:\n",
    "        fieldDir = os.path.join(fitsDir, field)\n",
    "        fitsFnames = glob(os.path.join(fieldDir, '*'))\n",
    "        for fname in fitsFnames:\n",
    "            temp = os.path.split(fname)[-1]\n",
    "            if not is_fits(temp):\n",
    "                os.remove(fname)\n",
    "                print(f\"{temp} has been removed bc it is not a .fits file\")\n",
    "\n",
    "def download_fits(fields):\n",
    "    apogeeUrl = \"https://data.sdss.org/sas/dr16/apogee/spectro/redux/r12/stars/apo25m\"\n",
    "    fitsDir = './fits_files'\n",
    "    \n",
    "    for field in fields:\n",
    "        targetSpectraUrl = os.path.join(apogeeUrl, field)\n",
    "        targetSpectraOutDir = os.path.join(fitsDir, field)\n",
    "        if not os.path.exists(targetSpectraOutDir):\n",
    "            os.makedirs(targetSpectraOutDir)\n",
    "        \n",
    "        soup = BeautifulSoup(requests.get(targetSpectraUrl).text)\n",
    "        for a in soup.find_all('a'):\n",
    "            link = a['href']\n",
    "            targetSpectraFname = os.path.join(targetSpectraOutDir, link)\n",
    "            if os.path.exists(targetSpectraFname):\n",
    "                continue\n",
    "            if (is_fits(link)):\n",
    "                targetSpectraLink = os.path.join(targetSpectraUrl, link)\n",
    "                try:\n",
    "                    wget.download(targetSpectraLink, out = targetSpectraFname)\n",
    "                except:\n",
    "                    print(f\"Something went wrong when downloading '{targetSpectraLink}'\")\n",
    "        print(f\"Finished downloading {field} spectra!\")\n",
    "    print(\"Finished!\")\n",
    "\n",
    "def download_fits_threaded(fields):\n",
    "    download_thread = Thread(target=download_fits, name=\"Fits Downloader\", args=[fields])\n",
    "    download_thread.start()\n",
    "    return download_thread\n",
    "\n",
    "def count_fits_files():\n",
    "    fitsDir = './fits_files'\n",
    "    print(f\"{'Dirname':<20} {'Count'}\")\n",
    "    print(\"-\"*(len('Dirname')+20))\n",
    "    total = 0\n",
    "    for r, d, files in os.walk(fitsDir):\n",
    "        root = os.path.split(r)[-1]\n",
    "        if not root == 'fits_files':\n",
    "            print(f\"{root:<20} {len(files)}\")\n",
    "            total += len(files)\n",
    "    print(f\"{'Total':<20} {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectraFields = [\"M15\", \"N6791\",  \"K2_C4_168-21\", \"060+00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS AGAIN LMAO\n",
    "# download_thread = download_fits_threaded(spectraFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this if download fails\n",
    "# clean_fits_directory(spectraFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (download_thread.is_alive()):\n",
    "#     print(\"Download is still running...\")\n",
    "count_fits_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fits_fname_by_idx(field, idx):\n",
    "    fitsDir = './fits_files'\n",
    "    fieldDir = os.path.join(fitsDir, field)\n",
    "    fullFname = glob(os.path.join(fieldDir, '*'))[idx]\n",
    "    return os.path.join(field, os.path.split(fullFname)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_start = 4.179\n",
    "wl_delta = 6e-06\n",
    "wl_count = 8575\n",
    "wavelengths = np.logspace(wl_start, wl_start+wl_delta*wl_count, wl_count, base=10)\n",
    "\n",
    "def get_fits_flux(fitsFname):\n",
    "    fitsDir = './fits_files'\n",
    "    fitsFname = os.path.join(fitsDir, fitsFname)\n",
    "    with fits.open(fitsFname) as hdul:\n",
    "        objID = hdul[0].header['OBJID']\n",
    "        hduFlux = hdul[1]\n",
    "        hduFluxErr = hdul[2]\n",
    "        hduMask = hdul[3]\n",
    "        \n",
    "        flux = np.array(hduFlux.data.reshape(-1, wl_count)[0])\n",
    "        fluxErr = np.array(hduFluxErr.data.reshape(-1, wl_count)[0])\n",
    "        \n",
    "        nullMask = (flux == 0)\n",
    "        binaryMask = (hduMask.data[0] & 0b100001111111) != 0\n",
    "        \n",
    "        flux[nullMask] = np.nan\n",
    "        fluxErr[nullMask] = np.nan\n",
    "        fluxErr[binaryMask] *= 10\n",
    "        \n",
    "        return objID, flux, fluxErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitsFname = get_fits_fname_by_idx(spectraFields[0], 0)\n",
    "objID, flux, fluxErr = get_fits_flux(fitsFname)\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.title(f\"Spectrum of {objID}\")\n",
    "plt.plot(wavelengths, flux)\n",
    "plt.ylim(plt.ylim())\n",
    "\n",
    "plt.fill_between(wavelengths, flux-fluxErr, flux+fluxErr, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2/Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_stars(fields):\n",
    "    fitsDir = './fits_files'\n",
    "    allStarFname = 'allStarLite-r12-l33.fits'\n",
    "    allStarPath = os.path.join(fitsDir, allStarFname)\n",
    "    \n",
    "    mainCols = [\n",
    "        'LOGG',\n",
    "        'TEFF',\n",
    "        'M_H',\n",
    "        'MG_FE',\n",
    "        'SI_FE'\n",
    "    ]\n",
    "    metaCols = [\n",
    "        'APOGEE_ID',\n",
    "        'FIELD',\n",
    "        'SNR',\n",
    "        'ASPCAPFLAGS'\n",
    "    ]\n",
    "    \n",
    "    errCols = [col + '_ERR' for col in mainCols]\n",
    "    \n",
    "    allStars = Table.read(allStarPath)\n",
    "    allStars = allStars[np.isin(allStars['FIELD'].astype(str), fields)]\n",
    "    allStars = allStars[metaCols + mainCols + errCols]\n",
    "    \n",
    "    snrMask = (allStars['SNR'] >= 50.0)\n",
    "    loggMask = (allStars['LOGG'] <= 4.0)\n",
    "    teffMask = (allStars['TEFF'] <= 5700.0)\n",
    "    m_hMask = (allStars['M_H'] >= -1.0)\n",
    "    \n",
    "    errMask = np.ones(len(allStars), dtype=bool)\n",
    "    for errField in errCols:\n",
    "        errMask = errMask&(allStars[errField] >= 0.0)\n",
    "    \n",
    "    allStars = allStars[snrMask & loggMask & teffMask & m_hMask & errMask]\n",
    "    allStars['index'] = np.arange(len(allStars))\n",
    "    \n",
    "    return allStars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainCols = [\n",
    "        'LOGG',\n",
    "        'TEFF',\n",
    "        'M_H',\n",
    "        'MG_FE',\n",
    "        'SI_FE'\n",
    "    ]\n",
    "allStars = load_all_stars(spectraFields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner(allStars[mainCols].to_pandas())\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_continuum(wavelengths):\n",
    "    with np.load('continuum_pixels_apogee.npz') as npz:\n",
    "        cpaWavelengths = npz['wavelength']\n",
    "        cpaIsContinuum = npz['is_continuum']\n",
    "    wavelengthsIsContinuum = (0.5 < np.around(np.interp(wavelengths, cpaWavelengths, cpaIsContinuum)))\n",
    "    return wavelengthsIsContinuum\n",
    "\n",
    "cpaChips = np.array([\n",
    "    [ 15170.8, 15785.0 ],\n",
    "    [ 15904.7, 16395.7 ],\n",
    "    [ 16503.3, 16930.5 ]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_normalize(wavelengths, flux, fluxErr, deg):\n",
    "    \n",
    "    wavelengthsIsContinuum = get_is_continuum(wavelengths)\n",
    "    isContinuumMask = wavelengthsIsContinuum & np.isfinite(flux)\n",
    "    \n",
    "    pseudoFlux = np.full(flux.shape, np.nan)\n",
    "    \n",
    "    for lo, hi in cpaChips:\n",
    "        rangeMask = (wavelengths >= lo) & (wavelengths <= hi)\n",
    "        mask = isContinuumMask & rangeMask\n",
    "        \n",
    "        chebCoeff = chebyshev.chebfit(wavelengths[mask], flux[mask], deg=deg, w=1/np.sqrt(fluxErr[mask]))\n",
    "        pseudoFlux[rangeMask] = chebyshev.chebval(wavelengths[rangeMask], chebCoeff)\n",
    "    \n",
    "    fluxNorm = flux/pseudoFlux\n",
    "    fluxErrNorm = fluxErr/pseudoFlux\n",
    "    \n",
    "    return fluxNorm, fluxErrNorm, pseudoFlux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_star_by_id(apogeeID):\n",
    "#     allStars = load_all_stars(spectraFields)\n",
    "    return allStars[allStars['APOGEE_ID'] == apogeeID]\n",
    "\n",
    "def get_fits_by_id(apogeeID):\n",
    "    fitsDir = './fits_files'\n",
    "    for r, d, files in os.walk(fitsDir):\n",
    "        for file in files:\n",
    "            if apogeeID in file:\n",
    "#                 print(r, d, file)\n",
    "#                 print(os.path.join(r, d, file))\n",
    "                field = os.path.split(r)[-1]\n",
    "                return get_fits_flux(os.path.join(field, file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pseudo_normalized(apogeeID, deg=5):\n",
    "    a, flux, fluxErr = get_fits_by_id(apogeeID)\n",
    "    \n",
    "    fluxNorm, fluxErrNorm, pseudoFlux = pseudo_normalize(wavelengths, flux, fluxErr, deg)\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(2,1, figsize=(16,8))\n",
    "    fig.suptitle(apogeeID)\n",
    "    ax1.set(title='Spectrum', ylabel='Flux')\n",
    "    ax1.plot(wavelengths, flux, lw=0.5, label='Spectrum')\n",
    "    ax1.set_ylim(ax1.get_ylim())\n",
    "    ax1.plot(wavelengths, pseudoFlux, label='Pseudo Continuum')\n",
    "    ax1.fill_between(wavelengths, flux-fluxErr, flux+fluxErr, alpha=0.15)\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(wavelengths, fluxNorm, lw=0.5)\n",
    "    ax2.axhline(1, 0, 1, c='k', lw=1)\n",
    "    ax2.set_ylim(ax2.get_ylim())\n",
    "    ax2.fill_between(wavelengths, fluxNorm-fluxErrNorm, fluxNorm+fluxErrNorm, alpha=0.15)\n",
    "    ax2.set(xlabel='Wavelength (Ang)', ylabel='NormalizedFlux', title=\"Pseudo-Normalized Spectrum\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apogeeID = '2M19395986+2341280'\n",
    "plot_pseudo_normalized(apogeeID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSpectraFname = 'allSpectra.npz'\n",
    "if os.path.exists(allSpectraFname):\n",
    "    print(f\"Loading spectra from {allSpectraFname}\")\n",
    "    with np.load(allSpectraFname) as allSpectraNPZ:\n",
    "        spectraFluxNorm = allSpectraNPZ['spectraFluxNorm']\n",
    "        spectraFluxErrNorm = allSpectraNPZ['spectraFluxErrNorm']\n",
    "        spectraPseudoNorm = allSpectraNPZ['spectraPseudoNorm']\n",
    "else:\n",
    "    spectraFluxNorm = np.empty((len(allStars), wl_count))\n",
    "    spectraFluxErrNorm = np.empty(spectraFluxNorm.shape)\n",
    "    spectraPseudoNorm = np.empty(spectraFluxNorm.shape)\n",
    "    \n",
    "    for i, star in enumerate(allStars):\n",
    "        apogeeID = star['APOGEE_ID']\n",
    "        a, flux, fluxErr = get_fits_by_id(apogeeID)\n",
    "        spectraFluxNorm[i], spectraFluxErrNorm[i], spectraPseudoNorm[i] = pseudo_normalize(wavelengths, flux,fluxErr,deg=5)\n",
    "        \n",
    "    np.savez_compressed(allSpectraFname, spectraFluxNorm = spectraFluxNorm, spectraFluxErrNorm = spectraFluxErrNorm, spectraPseudoNorm=spectraPseudoNorm)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectraFluxNorm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(283576)\n",
    "idxs = np.arange(len(allStars))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "middle = len(allStars)//2\n",
    "trainIdxs = idxs[:middle]\n",
    "valIdxs = idxs[middle:]\n",
    "\n",
    "trainStars = allStars[trainIdxs]\n",
    "trainFluxNorm = spectraFluxNorm[trainIdxs]\n",
    "trainFluxErrNorm = spectraFluxErrNorm[trainIdxs]\n",
    "trainPseudoNorm = spectraPseudoNorm[trainIdxs]\n",
    "\n",
    "valStars = allStars[valIdxs]\n",
    "valFluxNorm = spectraFluxNorm[valIdxs]\n",
    "valFluxErrNorm = spectraFluxErrNorm[valIdxs]\n",
    "valPseudoNorm = spectraPseudoNorm[valIdxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "49 in trainIdxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = pp.StandardScaler().fit(trainStars[mainCols].to_pandas())\n",
    "polynomializer = pp.PolynomialFeatures(include_bias = True, degree = 2)\n",
    "\n",
    "def transform_features(features):\n",
    "    features = features[mainCols]\n",
    "    if not isinstance(features, pd.DataFrame):\n",
    "        features = features.to_pandas()\n",
    "    features = normalizer.transform(features)\n",
    "    features = polynomializer.fit_transform(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(flux, fluxErr, fluxHat):\n",
    "    sigmas = np.logspace(-4, 0, num = 50, base = 10)\n",
    "    errMask = np.isfinite(fluxErr)\n",
    "    r = (flux[errMask] - fluxHat[errMask])[:,None]\n",
    "    outerSum = np.add.outer(fluxErr[errMask]**2, sigmas**2)\n",
    "    prob = np.log(outerSum).sum(axis=0) + (r**2/outerSum).sum(axis=0)\n",
    "    return sigmas[np.argmax(-prob)]\n",
    "    \n",
    "def fit_model(features, flux, fluxErr):\n",
    "    thetas = np.full((wl_count, features.shape[1]), np.nan)\n",
    "    sigmas = np.full(wl_count, np.nan)\n",
    "    \n",
    "    model = lm.LinearRegression(fit_intercept = False)\n",
    "    \n",
    "    for n in tqdm(range(wl_count)):\n",
    "        pixelFlux = np.nan_to_num(flux[:,n], nan=0.0, copy=True)\n",
    "        pixelFluxErr = np.nan_to_num(fluxErr[:,n], nan=np.inf, copy=True)\n",
    "#         print(pixelFlux)\n",
    "#         print(pixelFluxErr)\n",
    "        model.fit(features, pixelFlux, sample_weight = 1/np.square(pixelFluxErr))\n",
    "        thetas[n] = model.coef_\n",
    "#         print(thetas)\n",
    "        pixelFluxHat = model.predict(features)\n",
    "        sigmas[n] = log_prob(pixelFlux, pixelFluxErr, pixelFluxHat)\n",
    "#         print(sigmas)\n",
    "#         break\n",
    "        \n",
    "    return thetas, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatures = transform_features(trainStars)\n",
    "thetas,sigmas = fit_model(trainFeatures, trainFluxNorm, trainFluxErrNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "for i in range(thetas.shape[1]):\n",
    "    plt.plot(thetas[:,i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spectra(spectra):\n",
    "    features = transform_features(spectra)\n",
    "    return features @ thetas.T, sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(apogeeID):\n",
    "    spectra = get_star_by_id(apogeeID)\n",
    "    predFlux, predFluxErr = predict_spectra(spectra)\n",
    "    \n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title(apogeeID)\n",
    "    plt.plot(wavelengths, predFlux[0], label='Predicted')\n",
    "    plt.fill_between(wavelengths, \n",
    "                     predFlux[0]-predFluxErr, \n",
    "                     predFlux[0]+predFluxErr, \n",
    "                     alpha = 0.2)\n",
    "    \n",
    "    idx = spectra[0]['index']\n",
    "    plt.plot(wavelengths, spectraFluxNorm[idx], label='Observed')\n",
    "    plt.fill_between(wavelengths, \n",
    "                     spectraFluxNorm[idx]-spectraFluxErrNorm[idx],\n",
    "                    spectraFluxNorm[idx]+spectraFluxErrNorm[idx],\n",
    "                    alpha=0.2)\n",
    "    plt.xlim((16000,16100))\n",
    "    plt.ylim((0.5, 1.5))\n",
    "    plt.xlabel('Wavelength (Ang)')\n",
    "    plt.ylabel('Normalized Flux')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fit('2M03533659+2512012')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vac2air(wave, sdssweb=False):\n",
    "    if sdssweb:\n",
    "        return wave/(1.+2.735182*10.**-4.+131.4182/wave**2.+2.76249*10.**8./wave**4.)\n",
    "    else:\n",
    "        return wave/(1.+0.05792105/(238.0185-(10000./wave)**2.)+0.00167917/(57.362-(10000./wave)**2.))\n",
    "\n",
    "    \n",
    "def air2vac(wave, sdssweb=False):\n",
    "    return sp.optimize.brentq(lambda x: vac2air(x,sdssweb=sdssweb)-wave,\n",
    "                           wave-20,wave+20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomialFeatureNames = np.array(polynomializer.get_feature_names(mainCols))\n",
    "def getFeatureGradient(feature):\n",
    "    featureMask = (polynomialFeatureNames == feature)\n",
    "    return thetas[:,featureMask]\n",
    "\n",
    "bands = {\n",
    "    'MG_FE' : [air2vac(l) for l in [15740.716,15748.9,15765.8,15879.5,\n",
    "                                  15886.2,15954.477]],\n",
    "    'SI_FE' : [air2vac(l) for l in [15361.161,15376.831,15833.602,15960.063,\n",
    "                                  16060.009,16094.787,16215.670,16680.770,\n",
    "                                  16828.159]]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybound = 0.3\n",
    "for col in mainCols:\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.title(f'{col} Gradient and Bands')\n",
    "    plt.plot(wavelengths, getFeatureGradient(col))\n",
    "    if col in bands:\n",
    "        for wl in bands[col]:\n",
    "            plt.axvline(wl, 0, 1, c='r')\n",
    "            \n",
    "    plt.ylim(-ybound, ybound)\n",
    "    plt.fill_between(wavelengths, -ybound, -ybound+sigmas, alpha=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_features(flux, fluxErr):\n",
    "    def fxn(_wavelengths, *params):\n",
    "        features = np.array(params).reshape(1, -1)\n",
    "        features = normalizer.transform(features)\n",
    "        features = polynomializer.fit_transform(features)\n",
    "        return (features @ thetas.T)[0]\n",
    "    \n",
    "    fluxGroundTruth = np.nan_to_num(flux, nan=0.0)\n",
    "    fluxErrGroundTruth = np.nan_to_num(fluxErr, nan=np.inf)\n",
    "\n",
    "    features, _ = sp.optimize.curve_fit(fxn, \n",
    "                                     wavelengths, \n",
    "                                     fluxGroundTruth, \n",
    "                                     sigma=fluxErrGroundTruth,\n",
    "                                     p0=normalizer.mean_,\n",
    "                                     method='trf')\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valStars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in mainCols:\n",
    "    valStars[f'{name}_HAT'] = np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, star in enumerate(tqdm(valStars)):\n",
    "    featuresHat = predict_features(valFluxNorm[idx], valFluxErrNorm[idx])\n",
    "    for name, hat in zip(mainCols, featuresHat):\n",
    "        star[f'{name}_HAT'] = hat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in tqdm(mainCols):\n",
    "    obs = valStars[col]\n",
    "    obsErr = valStars[f'{col}_ERR']\n",
    "    hat = valStars[f'{col}_HAT']\n",
    "    minmax = np.array([np.nanmin(hat), np.nanmax(hat)])\n",
    "    \n",
    "    modelErr = np.nanstd(obs-hat, ddof=1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,10), gridspec_kw={'height_ratios':[3,1]})\n",
    "    ax1.set(title=f'Actual vs. Predicted {col}', xlabel='Predicted', ylabel='Actual')\n",
    "    ax1.errorbar(hat, obs, yerr=obsErr, fmt='.', alpha=0.5)\n",
    "    ax1.plot(minmax, minmax, color='k', alpha=0.5)\n",
    "    \n",
    "    ax2.set(title=f'Residual {col}', xlabel='Predicted', ylabel='Residual')\n",
    "    ax2.errorbar(hat, obs-hat, yerr=obsErr, fmt='.', alpha=0.5, color='r')\n",
    "    ax2.axhline(0,0,1,c='k', alpha=0.5)\n",
    "    \n",
    "    plt.show()\n",
    "    print(f\"=\"*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullErr = np.zeros(len(valStars))\n",
    "for col in tqdm(mainCols):\n",
    "    obs = valStars[col]\n",
    "    err = np.nan_to_num((obs - valStars[f'{col}_HAT']) ** 2 / len(valStars), nan=0)\n",
    "    fullErr += err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst10 = fullErr.argsort()[-10:]\n",
    "worst10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for worst in tqdm(worst10):\n",
    "    plot_fit(valStars['APOGEE_ID'][worst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_mist_models\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isocmd0 = read_mist_models.ISOCMD('MIST/MIST_iso_6069433b9817c.iso.cmd').isocmds[0]\n",
    "isocmdN1 = read_mist_models.ISOCMD('MIST/MIST_iso_6069435f0b4f1.iso.cmd').isocmds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Kiel Diagram for Validation Stars\")\n",
    "plt.xlabel('TEFF')\n",
    "plt.ylabel('LOGG')\n",
    "cmap = cm.get_cmap('coolwarm')\n",
    "vmin, vmax = -1, 0.5\n",
    "cmap_scaled = lambda x: cmap((x - vmin)/(vmax - vmin))\n",
    "\n",
    "plt.scatter(valStars['TEFF_HAT'], \n",
    "            valStars['LOGG_HAT'], \n",
    "            c=valStars['M_H_HAT'], \n",
    "            cmap=cmap)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlim(plt.xlim()[::-1])\n",
    "plt.ylim(plt.ylim()[::-1])\n",
    "\n",
    "plt.plot(10**isocmd0['log_Teff'], \n",
    "         isocmd0['log_g'], \n",
    "         label='M_H=0',\n",
    "         c=cmap_scaled(0))\n",
    "plt.plot(10**isocmdN1['log_Teff'], \n",
    "         isocmdN1['log_g'], \n",
    "         label='M_H=-1',\n",
    "         c=cmap_scaled(-1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysteryID, mysteryFlux, mysteryFluxErr = get_fits_flux('mystery_spec_wiped.fits')\n",
    "plot_pseudo_normalized(apogeeID, deg=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysteryFluxNorm, mysteryFluxErrNorm, _ = pseudo_normalize(wavelengths, mysteryFlux, mysteryFluxErr, deg=5)\n",
    "mysteryHat = predict_features(mysteryFluxNorm, mysteryFluxErrNorm)\n",
    "for name, hat in zip(mainCols, mysteryHat):\n",
    "     print(f'{name} = {hat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    labels = pm.Uniform('labels', lower=-10, upper=10, shape=(5,))\n",
    "    polyFeatures = (labels**polynomializer.powers_).prod(axis=1, keepdims=True)\n",
    "    fluxPred = pm.math.dot(polyFeatures.T, thetas)\n",
    "    \n",
    "    sigma = np.nan_to_num(np.sqrt(sigmas**2 + mysteryFluxErrNorm**2), nan=1e10)\n",
    "    \n",
    "    fluxObs = pm.Normal('fluxObs',\n",
    "                        mu = fluxPred,\n",
    "                        sigma = sigma,\n",
    "                        observed = np.nan_to_num(mysteryFluxErrNorm, nan=0))\n",
    "    \n",
    "\n",
    "    \n",
    "    trace = pm.sample(\n",
    "        tune=500,\n",
    "        draws=1000,\n",
    "        chains=chains,\n",
    "        cores=2\n",
    "    )\n",
    "    \n",
    "    untransformedLabels = normalizer.inverse_transform(trace['labels'])\n",
    "    traceDict = {\n",
    "        col: untransformedLabels[:, i].reshape(chains, -1) for i, col in enumerate(mainCols)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
